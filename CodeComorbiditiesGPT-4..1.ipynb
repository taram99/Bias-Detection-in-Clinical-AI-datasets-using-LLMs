{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "519c8c79-6f5a-467b-bbe9-072f40db0529",
   "metadata": {},
   "source": [
    "# GPT-4.1 programming code responses test for comorbidities dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb3c1c-ab17-42cd-8675-1cc05f903dd7",
   "metadata": {},
   "source": [
    "### Prompt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebff6c61-5bbf-4c9f-8f1f-d63e6aee819b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group\n",
      "black_0    12196.0\n",
      "black_1    12196.0\n",
      "white_0    12196.0\n",
      "white_1    12196.0\n",
      "Name: sample_weight, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Old code provided by LLM:\n",
    "#Reweighting:\n",
    "#sample_weight = total_samples / (n_groups * group_count[group_label])\n",
    "\n",
    "#new code\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load your data\n",
    "df = pd.read_csv(\"data_new.csv\")\n",
    "\n",
    "# 2. Pick your grouping.  For example, by race:\n",
    "#   —or— by the race×gender interaction:\n",
    "df['group'] = df['race'] + \"_\" + df['dem_female'].astype(str)\n",
    "\n",
    "# 3. Compute counts\n",
    "total_samples = len(df)\n",
    "group_counts  = df['group'].value_counts()        # Series: index=group_label, |value=count\n",
    "n_groups      = group_counts.size                 # how many distinct groups\n",
    "\n",
    "# 4. Build the weight map\n",
    "#    total_samples / (n_groups * count_for_each_group)\n",
    "weight_map = {\n",
    "    grp: total_samples / (n_groups * cnt)\n",
    "    for grp, cnt in group_counts.items()\n",
    "}\n",
    "\n",
    "# 5. Assign a sample_weight column\n",
    "df['sample_weight'] = df['group'].map(weight_map)\n",
    "\n",
    "# 6. Quick sanity check: each group’s total weight should be ≈ total_samples/n_groups\n",
    "group_weight_sums = df.groupby('group')['sample_weight'].sum()\n",
    "print(group_weight_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431a8201-f5a4-4f4b-9d26-7c6275a4cf07",
   "metadata": {},
   "source": [
    "## Output\n",
    "All four groups summing to 12 196 means that out of 48 784 total samples split across four groups, each group’s weights add up to exactly 48 784 ÷ 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd987884-681d-4893-b027-a1900077f0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class counts: {0: 48332, 1: 452}\n",
      "Resampled class counts: {0: 48332, 1: 48332}\n"
     ]
    }
   ],
   "source": [
    "#old code provided by LLM\n",
    "# from imblearn.over_sampling import SMOTENC\n",
    "#X_resampled, y_resampled = SMOTENC(categorical_features=[group_index], random_state=0).fit_resample(X, y)\n",
    "\n",
    "#new code:\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "# 1. Load and select features/target\n",
    "df = pd.read_csv(\"data_new.csv\")\n",
    "X = df[['risk_score_t', 'race', 'dem_female']]   # risk_score_t is numeric; race & dem_female are categorical\n",
    "y = df['program_enrolled_t']\n",
    "\n",
    "# 2. Encode categorical columns as integer codes (SMOTENC expects integer‐coded cats, not one‐hot)\n",
    "categorical_cols = ['race', 'dem_female']\n",
    "X_enc = X.copy()\n",
    "for col in categorical_cols:\n",
    "    X_enc[col] = X_enc[col].astype('category').cat.codes\n",
    "\n",
    "# 3. Figure out the indices of those categorical columns\n",
    "cat_indices = [X_enc.columns.get_loc(col) for col in categorical_cols]\n",
    "\n",
    "# 4. Instantiate SMOTENC with those indices\n",
    "smote_nc = SMOTENC(categorical_features=cat_indices, random_state=42)\n",
    "\n",
    "# 5. Fit & resample\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X_enc, y)\n",
    "\n",
    "print(\"Original class counts:\", y.value_counts().to_dict())\n",
    "print(\"Resampled class counts:\", pd.Series(y_resampled).value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca882693-b981-455e-8130-6a9980592865",
   "metadata": {},
   "source": [
    "## Output\n",
    "The SMOTENC procedure took the original set of 48 332 negatives (class 0) and just 452 positives (class 1) and synthetically generated new minority samples until both classes had 48 332 examples. In other words, it has perfectly balanced the dataset by oversampling the under-represented positive cases while respecting the categorical nature of “race” and “dem_female.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762d0e98-663a-41cc-8612-e8595bcd5b97",
   "metadata": {},
   "source": [
    "### comment \n",
    "this was the only code that was given\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
